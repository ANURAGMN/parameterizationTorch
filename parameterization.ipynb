{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4266753b-ca21-4e1b-a3c6-8d90d81470b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "\n",
    "class PositiveWeightParametrization(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PositiveWeightParametrization, self).__init__()\n",
    "\n",
    "    def forward(self, weight):\n",
    "        return torch.abs(weight)  # Ensure weights are positive by taking the absolute value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93038975-36f4-4345-aa00-a472a285f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LargerModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d798148b-b63c-4af0-a3e6-630e5b521d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametrizedLinear(\n",
       "  in_features=128, out_features=10, bias=True\n",
       "  (parametrizations): ModuleDict(\n",
       "    (weight): ParametrizationList(\n",
       "      (0): PositiveWeightParametrization()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LargerModel()\n",
    "\n",
    "# Register the positive weight parameterization for each linear layer\n",
    "parametrize.register_parametrization(model.fc1, \"weight\", PositiveWeightParametrization())\n",
    "parametrize.register_parametrization(model.fc2, \"weight\", PositiveWeightParametrization())\n",
    "parametrize.register_parametrization(model.fc3, \"weight\", PositiveWeightParametrization())\n",
    "parametrize.register_parametrization(model.fc4, \"weight\", PositiveWeightParametrization())\n",
    "parametrize.register_parametrization(model.fc5, \"weight\", PositiveWeightParametrization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744015f6-842d-4563-bb88-70aae6136db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output of the model:\n",
      "tensor([[  27.9941,   27.2058,   30.0709,   31.2678,   26.0386,   27.4388,\n",
      "           27.5907,   28.5043,   27.9966,   25.6480],\n",
      "        [ 663.8464,  642.5631,  710.6545,  739.7053,  615.9739,  648.6669,\n",
      "          651.1768,  672.2945,  661.3011,  607.4319],\n",
      "        [ 244.9572,  237.1760,  262.2976,  272.9989,  227.3346,  239.4125,\n",
      "          240.3699,  248.1767,  244.0919,  224.1627],\n",
      "        [  58.0053,   56.2498,   62.1939,   64.7053,   53.8828,   56.7589,\n",
      "           57.0240,   58.8898,   57.8883,   53.1073],\n",
      "        [1922.6731, 1860.8177, 2058.0427, 2142.2400, 1783.9044, 1878.5455,\n",
      "         1885.7285, 1946.8411, 1915.0891, 1759.2177]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "x = torch.randn(5, 128)  # Batch of 5 samples, each with 128 features\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "\n",
    "print(\"\\nOutput of the model:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6483ecb-8362-41f5-a686-57cc993d9f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights of fc1 are positive: tensor(True)\n",
      "Weights of fc2 are positive: tensor(True)\n",
      "Weights of fc3 are positive: tensor(True)\n",
      "Weights of fc4 are positive: tensor(True)\n",
      "Weights of fc5 are positive: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# Verify that the weights are positive\n",
    "def check_positive_weights(layer):\n",
    "    weights = layer.weight\n",
    "    return torch.all(weights >= 0)\n",
    "\n",
    "print(\"\\nWeights of fc1 are positive:\", check_positive_weights(model.fc1))\n",
    "print(\"Weights of fc2 are positive:\", check_positive_weights(model.fc2))\n",
    "print(\"Weights of fc3 are positive:\", check_positive_weights(model.fc3))\n",
    "print(\"Weights of fc4 are positive:\", check_positive_weights(model.fc4))\n",
    "print(\"Weights of fc5 are positive:\", check_positive_weights(model.fc5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093fc7b9-b192-4a57-a97d-0c55b40fbfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LargerModelWithoutParam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LargerModelWithoutParam, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c7144e-ba5a-4217-876c-067f6865046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_positive_weights(model):\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            with torch.no_grad():\n",
    "                layer.weight.copy_(torch.abs(layer.weight))\n",
    "\n",
    "# Initialize the model\n",
    "model_without_param = LargerModelWithoutParam()\n",
    "\n",
    "# Apply positive weights manually\n",
    "apply_positive_weights(model_without_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3acedbfe-86bc-4a86-8400-4150b1129120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output of the model:\n",
      "tensor([[4309.2729, 4071.0974, 4248.9531, 3724.5676, 3976.8716, 3858.1816,\n",
      "         4260.5449, 4196.9556, 4418.8042, 4062.3809],\n",
      "        [3692.2959, 3488.2073, 3640.6135, 3191.3105, 3407.4746, 3305.7998,\n",
      "         3650.5405, 3596.0508, 3786.1482, 3480.7605],\n",
      "        [ 856.6445,  809.2256,  844.6451,  740.4554,  790.5018,  767.0203,\n",
      "          846.9155,  834.2922,  878.4243,  807.6210],\n",
      "        [ 940.3215,  888.2793,  927.1459,  812.7800,  867.7210,  841.9325,\n",
      "          929.6431,  915.7894,  964.2242,  886.5009],\n",
      "        [3580.0078, 3382.1211, 3529.8967, 3094.2617, 3303.8496, 3205.2664,\n",
      "         3539.5215, 3486.6902, 3671.0056, 3374.9111]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "x = torch.randn(5, 128)  # Batch of 5 samples, each with 128 features\n",
    "\n",
    "# Forward pass\n",
    "output = model_without_param(x)\n",
    "\n",
    "print(\"\\nOutput of the model:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1fbf28c-09ae-43b2-8150-29b868e020d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights of fc1 are positive: tensor(True)\n",
      "Weights of fc2 are positive: tensor(True)\n",
      "Weights of fc3 are positive: tensor(True)\n",
      "Weights of fc4 are positive: tensor(True)\n",
      "Weights of fc5 are positive: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# Verify that the weights are positive\n",
    "def check_positive_weights(layer):\n",
    "    weights = layer.weight\n",
    "    return torch.all(weights >= 0)\n",
    "\n",
    "print(\"\\nWeights of fc1 are positive:\", check_positive_weights(model_without_param.fc1))\n",
    "print(\"Weights of fc2 are positive:\", check_positive_weights(model_without_param.fc2))\n",
    "print(\"Weights of fc3 are positive:\", check_positive_weights(model_without_param.fc3))\n",
    "print(\"Weights of fc4 are positive:\", check_positive_weights(model_without_param.fc4))\n",
    "print(\"Weights of fc5 are positive:\", check_positive_weights(model_without_param.fc5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff920a8-ba80-4704-a579-ebd096a9fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the models\n",
    "class LargerModelWithoutParam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LargerModelWithoutParam, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "class PositiveWeightParametrization(nn.Module):\n",
    "    def forward(self, X):\n",
    "        return torch.abs(X)\n",
    "\n",
    "def apply_positive_weights(model):\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            with torch.no_grad():\n",
    "                layer.weight.copy_(torch.abs(layer.weight))\n",
    "\n",
    "# Initialize models\n",
    "model_without_param = LargerModelWithoutParam()\n",
    "\n",
    "# Apply positive weights manually\n",
    "apply_positive_weights(model_without_param)\n",
    "\n",
    "# Generate random weights for visualization\n",
    "def get_weight_distributions(model):\n",
    "    weights = []\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            weights.append(layer.weight.detach().cpu().numpy().flatten())\n",
    "    return weights\n",
    "\n",
    "# Get weight distributions\n",
    "weights_before = get_weight_distributions(model_without_param)\n",
    "\n",
    "# Apply positive weights again for a visualization\n",
    "apply_positive_weights(model_without_param)\n",
    "weights_after = get_weight_distributions(model_without_param)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot before constraint\n",
    "plt.subplot(1, 2, 1)\n",
    "for weight in weights_before:\n",
    "    plt.hist(weight, bins=50, alpha=0.6)\n",
    "plt.title('Weight Distribution Before Constraint')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Plot after constraint\n",
    "plt.subplot(1, 2, 2)\n",
    "for weight in weights_after:\n",
    "    plt.hist(weight, bins=50, alpha=0.6)\n",
    "plt.title('Weight Distribution After Constraint')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799580a-a7ec-422b-98bf-b3bd2a1a7382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
